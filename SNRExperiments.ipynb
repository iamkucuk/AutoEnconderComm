{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600716823227",
   "display_name": "Python 3.7.7 64-bit ('commtf': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, GaussianNoise, Lambda, Dropout, concatenate, LSTM, Add, Multiply, Layer\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from keras.utils import plot_model\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from utils import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = K.constant([[1, 1]])\n",
    "SNR1 = 7\n",
    "SNR2 = 7\n",
    "SNRs = [SNR1, SNR2]\n",
    "ebno = [calc_ebno(SNR) for SNR in SNRs]\n",
    "\n",
    "k = 2\n",
    "n_channel = 2\n",
    "M = 2 ** k\n",
    "k = int(k)\n",
    "R = k / n_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /usr/local/envs/commtf/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\n"
    }
   ],
   "source": [
    "input_signal1 = Input(shape=(M,), name=\"input1\")\n",
    "input_signal2 = Input(shape=(M,), name=\"input2\")\n",
    "encoder1 = create_encoder([M, n_channel], name=\"encoder1\", activations=[\"relu\", \"linear\"])\n",
    "encoder2 = create_encoder([M, n_channel], name=\"encoder2\", activations=[\"relu\", \"linear\"])\n",
    "\n",
    "combiner = create_combiner(layer_sizes=[n_channel * 4, n_channel], activations=[\"relu\", \"tanh\"], name=\"combiner\")\n",
    "\n",
    "signal_input2 = create_inputs(R=R, H=H, t=0, k=1, ebno=ebno, name=\"transmit2\")\n",
    "signal_input1 = create_inputs(R=R, H=H, t=0, k=0, ebno=ebno, name=\"transmit1\")\n",
    "\n",
    "decoder1 = create_decoder([M * 4, M * 2, M], name=\"decoder1\", activation=\"relu\")\n",
    "\n",
    "decoder2 = create_decoder([M * 4, M * 2, M], name=\"decoder2\", activation=\"relu\")\n",
    "\n",
    "x1 = encoder1(input_signal1)\n",
    "x2 = encoder1(input_signal2)\n",
    "x = concatenate([x1, x2], axis=1)\n",
    "x = combiner(x)\n",
    "x1 = signal_input1(x)\n",
    "x2 = signal_input2(x)\n",
    "out1 = decoder1(x1)\n",
    "out2 = decoder2(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput1 (InputLayer)             (None, 4)            0                                            \n__________________________________________________________________________________________________\ninput2 (InputLayer)             (None, 4)            0                                            \n__________________________________________________________________________________________________\nencoder1 (Sequential)           (None, 2)            34          input1[0][0]                     \n                                                                 input2[0][0]                     \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 4)            0           encoder1[1][0]                   \n                                                                 encoder1[2][0]                   \n__________________________________________________________________________________________________\ncombiner (Sequential)           (None, 2)            62          concatenate_1[0][0]              \n__________________________________________________________________________________________________\ntransmit1 (Lambda)              (None, 2)            0           combiner[1][0]                   \n__________________________________________________________________________________________________\ntransmit2 (Lambda)              (None, 2)            0           combiner[1][0]                   \n__________________________________________________________________________________________________\ndecoder1 (Sequential)           (None, 4)            220         transmit1[0][0]                  \n__________________________________________________________________________________________________\ndecoder2 (Sequential)           (None, 4)            220         transmit2[0][0]                  \n==================================================================================================\nTotal params: 536\nTrainable params: 528\nNon-trainable params: 8\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "model = Model(inputs=[input_signal1, input_signal2], outputs=[out1, out2])\n",
    "model.summary()\n",
    "alpha = K.variable(.5)\n",
    "\n",
    "optim = SGD(momentum=.9)\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=[\"categorical_crossentropy\", \"categorical_crossentropy\"],\n",
    "            loss_weights=[alpha, (1 - alpha)], metrics=[\"accuracy\", BER])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ": 0.8822 - val_decoder2_BER: 0.0589\nEpoch 561/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2901 - decoder1_loss: 0.2897 - decoder2_loss: 0.2904 - decoder1_accuracy: 0.8812 - decoder1_BER: 0.0594 - decoder2_accuracy: 0.8807 - decoder2_BER: 0.0596 - val_loss: 0.2882 - val_decoder1_loss: 0.2891 - val_decoder2_loss: 0.2873 - val_decoder1_accuracy: 0.8821 - val_decoder1_BER: 0.0589 - val_decoder2_accuracy: 0.8825 - val_decoder2_BER: 0.0587\nEpoch 562/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2895 - decoder1_loss: 0.2892 - decoder2_loss: 0.2899 - decoder1_accuracy: 0.8823 - decoder1_BER: 0.0589 - decoder2_accuracy: 0.8820 - decoder2_BER: 0.0590 - val_loss: 0.2883 - val_decoder1_loss: 0.2884 - val_decoder2_loss: 0.2883 - val_decoder1_accuracy: 0.8819 - val_decoder1_BER: 0.0590 - val_decoder2_accuracy: 0.8824 - val_decoder2_BER: 0.0588\nEpoch 563/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2882 - decoder1_loss: 0.2878 - decoder2_loss: 0.2885 - decoder1_accuracy: 0.8819 - decoder1_BER: 0.0591 - decoder2_accuracy: 0.8823 - decoder2_BER: 0.0588 - val_loss: 0.2883 - val_decoder1_loss: 0.2881 - val_decoder2_loss: 0.2885 - val_decoder1_accuracy: 0.8825 - val_decoder1_BER: 0.0587 - val_decoder2_accuracy: 0.8816 - val_decoder2_BER: 0.0592\nEpoch 564/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2883 - decoder1_loss: 0.2883 - decoder2_loss: 0.2883 - decoder1_accuracy: 0.8818 - decoder1_BER: 0.0591 - decoder2_accuracy: 0.8834 - decoder2_BER: 0.0583 - val_loss: 0.2888 - val_decoder1_loss: 0.2884 - val_decoder2_loss: 0.2891 - val_decoder1_accuracy: 0.8817 - val_decoder1_BER: 0.0591 - val_decoder2_accuracy: 0.8823 - val_decoder2_BER: 0.0589\nEpoch 565/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2903 - decoder1_loss: 0.2880 - decoder2_loss: 0.2925 - decoder1_accuracy: 0.8819 - decoder1_BER: 0.0590 - decoder2_accuracy: 0.8804 - decoder2_BER: 0.0598 - val_loss: 0.2870 - val_decoder1_loss: 0.2863 - val_decoder2_loss: 0.2876 - val_decoder1_accuracy: 0.8835 - val_decoder1_BER: 0.0582 - val_decoder2_accuracy: 0.8833 - val_decoder2_BER: 0.0583\nEpoch 566/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2885 - decoder1_loss: 0.2867 - decoder2_loss: 0.2902 - decoder1_accuracy: 0.8828 - decoder1_BER: 0.0586 - decoder2_accuracy: 0.8814 - decoder2_BER: 0.0593 - val_loss: 0.2895 - val_decoder1_loss: 0.2901 - val_decoder2_loss: 0.2888 - val_decoder1_accuracy: 0.8819 - val_decoder1_BER: 0.0590 - val_decoder2_accuracy: 0.8824 - val_decoder2_BER: 0.0588\nEpoch 567/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2883 - decoder1_loss: 0.2886 - decoder2_loss: 0.2879 - decoder1_accuracy: 0.8816 - decoder1_BER: 0.0592 - decoder2_accuracy: 0.8823 - decoder2_BER: 0.0588 - val_loss: 0.2893 - val_decoder1_loss: 0.2885 - val_decoder2_loss: 0.2901 - val_decoder1_accuracy: 0.8831 - val_decoder1_BER: 0.0585 - val_decoder2_accuracy: 0.8812 - val_decoder2_BER: 0.0594\nEpoch 568/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2890 - decoder1_loss: 0.2879 - decoder2_loss: 0.2900 - decoder1_accuracy: 0.8815 - decoder1_BER: 0.0592 - decoder2_accuracy: 0.8817 - decoder2_BER: 0.0591 - val_loss: 0.2869 - val_decoder1_loss: 0.2870 - val_decoder2_loss: 0.2869 - val_decoder1_accuracy: 0.8827 - val_decoder1_BER: 0.0586 - val_decoder2_accuracy: 0.8833 - val_decoder2_BER: 0.0583\nEpoch 569/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2878 - decoder1_loss: 0.2880 - decoder2_loss: 0.2877 - decoder1_accuracy: 0.8827 - decoder1_BER: 0.0587 - decoder2_accuracy: 0.8824 - decoder2_BER: 0.0588 - val_loss: 0.2889 - val_decoder1_loss: 0.2887 - val_decoder2_loss: 0.2891 - val_decoder1_accuracy: 0.8823 - val_decoder1_BER: 0.0589 - val_decoder2_accuracy: 0.8822 - val_decoder2_BER: 0.0589\nEpoch 570/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2868 - decoder1_loss: 0.2883 - decoder2_loss: 0.2854 - decoder1_accuracy: 0.8821 - decoder1_BER: 0.0589 - decoder2_accuracy: 0.8843 - decoder2_BER: 0.0578 - val_loss: 0.2887 - val_decoder1_loss: 0.2888 - val_decoder2_loss: 0.2886 - val_decoder1_accuracy: 0.8820 - val_decoder1_BER: 0.0590 - val_decoder2_accuracy: 0.8817 - val_decoder2_BER: 0.0592\nEpoch 571/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2875 - decoder1_loss: 0.2860 - decoder2_loss: 0.2890 - decoder1_accuracy: 0.8831 - decoder1_BER: 0.0585 - decoder2_accuracy: 0.8816 - decoder2_BER: 0.0592 - val_loss: 0.2875 - val_decoder1_loss: 0.2877 - val_decoder2_loss: 0.2873 - val_decoder1_accuracy: 0.8830 - val_decoder1_BER: 0.0585 - val_decoder2_accuracy: 0.8831 - val_decoder2_BER: 0.0585\nEpoch 572/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2886 - decoder1_loss: 0.2895 - decoder2_loss: 0.2876 - decoder1_accuracy: 0.8823 - decoder1_BER: 0.0589 - decoder2_accuracy: 0.8823 - decoder2_BER: 0.0588 - val_loss: 0.2857 - val_decoder1_loss: 0.2848 - val_decoder2_loss: 0.2865 - val_decoder1_accuracy: 0.8837 - val_decoder1_BER: 0.0582 - val_decoder2_accuracy: 0.8832 - val_decoder2_BER: 0.0584\nEpoch 573/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2888 - decoder1_loss: 0.2887 - decoder2_loss: 0.2888 - decoder1_accuracy: 0.8825 - decoder1_BER: 0.0587 - decoder2_accuracy: 0.8827 - decoder2_BER: 0.0587 - val_loss: 0.2866 - val_decoder1_loss: 0.2857 - val_decoder2_loss: 0.2876 - val_decoder1_accuracy: 0.8831 - val_decoder1_BER: 0.0585 - val_decoder2_accuracy: 0.8823 - val_decoder2_BER: 0.0588\nEpoch 574/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2881 - decoder1_loss: 0.2886 - decoder2_loss: 0.2877 - decoder1_accuracy: 0.8823 - decoder1_BER: 0.0589 - decoder2_accuracy: 0.8826 - decoder2_BER: 0.0587 - val_loss: 0.2895 - val_decoder1_loss: 0.2888 - val_decoder2_loss: 0.2901 - val_decoder1_accuracy: 0.8824 - val_decoder1_BER: 0.0588 - val_decoder2_accuracy: 0.8813 - val_decoder2_BER: 0.0593\nEpoch 575/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2894 - decoder1_loss: 0.2895 - decoder2_loss: 0.2893 - decoder1_accuracy: 0.8822 - decoder1_BER: 0.0589 - decoder2_accuracy: 0.8828 - decoder2_BER: 0.0586 - val_loss: 0.2895 - val_decoder1_loss: 0.2878 - val_decoder2_loss: 0.2912 - val_decoder1_accuracy: 0.8828 - val_decoder1_BER: 0.0586 - val_decoder2_accuracy: 0.8816 - val_decoder2_BER: 0.0592\nEpoch 576/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2875 - decoder1_loss: 0.2869 - decoder2_loss: 0.2881 - decoder1_accuracy: 0.8827 - decoder1_BER: 0.0587 - decoder2_accuracy: 0.8820 - decoder2_BER: 0.0590 - val_loss: 0.2885 - val_decoder1_loss: 0.2884 - val_decoder2_loss: 0.2887 - val_decoder1_accuracy: 0.8819 - val_decoder1_BER: 0.0591 - val_decoder2_accuracy: 0.8824 - val_decoder2_BER: 0.0588\nEpoch 577/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2879 - decoder1_loss: 0.2871 - decoder2_loss: 0.2886 - decoder1_accuracy: 0.8830 - decoder1_BER: 0.0585 - decoder2_accuracy: 0.8823 - decoder2_BER: 0.0589 - val_loss: 0.2896 - val_decoder1_loss: 0.2910 - val_decoder2_loss: 0.2882 - val_decoder1_accuracy: 0.8813 - val_decoder1_BER: 0.0593 - val_decoder2_accuracy: 0.8829 - val_decoder2_BER: 0.0586\nEpoch 578/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2886 - decoder1_loss: 0.2887 - decoder2_loss: 0.2885 - decoder1_accuracy: 0.8821 - decoder1_BER: 0.0589 - decoder2_accuracy: 0.8829 - decoder2_BER: 0.0585 - val_loss: 0.2879 - val_decoder1_loss: 0.2868 - val_decoder2_loss: 0.2891 - val_decoder1_accuracy: 0.8832 - val_decoder1_BER: 0.0584 - val_decoder2_accuracy: 0.8817 - val_decoder2_BER: 0.0591\nEpoch 579/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2907 - decoder1_loss: 0.2901 - decoder2_loss: 0.2913 - decoder1_accuracy: 0.8817 - decoder1_BER: 0.0592 - decoder2_accuracy: 0.8809 - decoder2_BER: 0.0595 - val_loss: 0.2882 - val_decoder1_loss: 0.2882 - val_decoder2_loss: 0.2882 - val_decoder1_accuracy: 0.8825 - val_decoder1_BER: 0.0588 - val_decoder2_accuracy: 0.8831 - val_decoder2_BER: 0.0585\nEpoch 580/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2878 - decoder1_loss: 0.2889 - decoder2_loss: 0.2867 - decoder1_accuracy: 0.8822 - decoder1_BER: 0.0589 - decoder2_accuracy: 0.8830 - decoder2_BER: 0.0585 - val_loss: 0.2885 - val_decoder1_loss: 0.2878 - val_decoder2_loss: 0.2892 - val_decoder1_accuracy: 0.8827 - val_decoder1_BER: 0.0586 - val_decoder2_accuracy: 0.8826 - val_decoder2_BER: 0.0587\nEpoch 581/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2887 - decoder1_loss: 0.2851 - decoder2_loss: 0.2922 - decoder1_accuracy: 0.8823 - decoder1_BER: 0.0588 - decoder2_accuracy: 0.8802 - decoder2_BER: 0.0599 - val_loss: 0.2881 - val_decoder1_loss: 0.2877 - val_decoder2_loss: 0.2885 - val_decoder1_accuracy: 0.8829 - val_decoder1_BER: 0.0586 - val_decoder2_accuracy: 0.8821 - val_decoder2_BER: 0.0590\nEpoch 582/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2893 - decoder1_loss: 0.2891 - decoder2_loss: 0.2895 - decoder1_accuracy: 0.8813 - decoder1_BER: 0.0594 - decoder2_accuracy: 0.8815 - decoder2_BER: 0.0592 - val_loss: 0.2899 - val_decoder1_loss: 0.2897 - val_decoder2_loss: 0.2901 - val_decoder1_accuracy: 0.8818 - val_decoder1_BER: 0.0591 - val_decoder2_accuracy: 0.8816 - val_decoder2_BER: 0.0592\nEpoch 583/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2888 - decoder1_loss: 0.2901 - decoder2_loss: 0.2876 - decoder1_accuracy: 0.8812 - decoder1_BER: 0.0594 - decoder2_accuracy: 0.8822 - decoder2_BER: 0.0589 - val_loss: 0.2885 - val_decoder1_loss: 0.2867 - val_decoder2_loss: 0.2903 - val_decoder1_accuracy: 0.8820 - val_decoder1_BER: 0.0590 - val_decoder2_accuracy: 0.8820 - val_decoder2_BER: 0.0590\nEpoch 584/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2901 - decoder1_loss: 0.2897 - decoder2_loss: 0.2905 - decoder1_accuracy: 0.8813 - decoder1_BER: 0.0593 - decoder2_accuracy: 0.8806 - decoder2_BER: 0.0597 - val_loss: 0.2888 - val_decoder1_loss: 0.2876 - val_decoder2_loss: 0.2899 - val_decoder1_accuracy: 0.8825 - val_decoder1_BER: 0.0587 - val_decoder2_accuracy: 0.8819 - val_decoder2_BER: 0.0591\nEpoch 585/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2882 - decoder1_loss: 0.2888 - decoder2_loss: 0.2876 - decoder1_accuracy: 0.8812 - decoder1_BER: 0.0594 - decoder2_accuracy: 0.8821 - decoder2_BER: 0.0590 - val_loss: 0.2893 - val_decoder1_loss: 0.2898 - val_decoder2_loss: 0.2889 - val_decoder1_accuracy: 0.8817 - val_decoder1_BER: 0.0592 - val_decoder2_accuracy: 0.8818 - val_decoder2_BER: 0.0591\nEpoch 586/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2894 - decoder1_loss: 0.2887 - decoder2_loss: 0.2901 - decoder1_accuracy: 0.8820 - decoder1_BER: 0.0590 - decoder2_accuracy: 0.8817 - decoder2_BER: 0.0592 - val_loss: 0.2891 - val_decoder1_loss: 0.2887 - val_decoder2_loss: 0.2894 - val_decoder1_accuracy: 0.8823 - val_decoder1_BER: 0.0589 - val_decoder2_accuracy: 0.8821 - val_decoder2_BER: 0.0590\nEpoch 587/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2889 - decoder1_loss: 0.2880 - decoder2_loss: 0.2898 - decoder1_accuracy: 0.8822 - decoder1_BER: 0.0589 - decoder2_accuracy: 0.8811 - decoder2_BER: 0.0594 - val_loss: 0.2889 - val_decoder1_loss: 0.2892 - val_decoder2_loss: 0.2885 - val_decoder1_accuracy: 0.8818 - val_decoder1_BER: 0.0591 - val_decoder2_accuracy: 0.8821 - val_decoder2_BER: 0.0589\nEpoch 588/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2895 - decoder1_loss: 0.2892 - decoder2_loss: 0.2897 - decoder1_accuracy: 0.8817 - decoder1_BER: 0.0591 - decoder2_accuracy: 0.8818 - decoder2_BER: 0.0591 - val_loss: 0.2889 - val_decoder1_loss: 0.2878 - val_decoder2_loss: 0.2901 - val_decoder1_accuracy: 0.8819 - val_decoder1_BER: 0.0591 - val_decoder2_accuracy: 0.8823 - val_decoder2_BER: 0.0588\nEpoch 589/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2897 - decoder1_loss: 0.2898 - decoder2_loss: 0.2896 - decoder1_accuracy: 0.8811 - decoder1_BER: 0.0595 - decoder2_accuracy: 0.8814 - decoder2_BER: 0.0593 - val_loss: 0.2893 - val_decoder1_loss: 0.2887 - val_decoder2_loss: 0.2899 - val_decoder1_accuracy: 0.8817 - val_decoder1_BER: 0.0591 - val_decoder2_accuracy: 0.8814 - val_decoder2_BER: 0.0593\nEpoch 590/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2871 - decoder1_loss: 0.2861 - decoder2_loss: 0.2880 - decoder1_accuracy: 0.8831 - decoder1_BER: 0.0584 - decoder2_accuracy: 0.8822 - decoder2_BER: 0.0589 - val_loss: 0.2873 - val_decoder1_loss: 0.2872 - val_decoder2_loss: 0.2873 - val_decoder1_accuracy: 0.8827 - val_decoder1_BER: 0.0587 - val_decoder2_accuracy: 0.8822 - val_decoder2_BER: 0.0589\nEpoch 591/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2870 - decoder1_loss: 0.2862 - decoder2_loss: 0.2878 - decoder1_accuracy: 0.8837 - decoder1_BER: 0.0582 - decoder2_accuracy: 0.8823 - decoder2_BER: 0.0589 - val_loss: 0.2883 - val_decoder1_loss: 0.2881 - val_decoder2_loss: 0.2885 - val_decoder1_accuracy: 0.8816 - val_decoder1_BER: 0.0592 - val_decoder2_accuracy: 0.8820 - val_decoder2_BER: 0.0590\nEpoch 592/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2881 - decoder1_loss: 0.2857 - decoder2_loss: 0.2905 - decoder1_accuracy: 0.8833 - decoder1_BER: 0.0583 - decoder2_accuracy: 0.8815 - decoder2_BER: 0.0592 - val_loss: 0.2904 - val_decoder1_loss: 0.2903 - val_decoder2_loss: 0.2905 - val_decoder1_accuracy: 0.8812 - val_decoder1_BER: 0.0594 - val_decoder2_accuracy: 0.8816 - val_decoder2_BER: 0.0592\nEpoch 593/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2895 - decoder1_loss: 0.2884 - decoder2_loss: 0.2906 - decoder1_accuracy: 0.8821 - decoder1_BER: 0.0589 - decoder2_accuracy: 0.8817 - decoder2_BER: 0.0592 - val_loss: 0.2881 - val_decoder1_loss: 0.2889 - val_decoder2_loss: 0.2873 - val_decoder1_accuracy: 0.8813 - val_decoder1_BER: 0.0593 - val_decoder2_accuracy: 0.8832 - val_decoder2_BER: 0.0584\nEpoch 594/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2895 - decoder1_loss: 0.2886 - decoder2_loss: 0.2904 - decoder1_accuracy: 0.8816 - decoder1_BER: 0.0592 - decoder2_accuracy: 0.8811 - decoder2_BER: 0.0595 - val_loss: 0.2877 - val_decoder1_loss: 0.2878 - val_decoder2_loss: 0.2876 - val_decoder1_accuracy: 0.8819 - val_decoder1_BER: 0.0590 - val_decoder2_accuracy: 0.8827 - val_decoder2_BER: 0.0587\nEpoch 595/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2895 - decoder1_loss: 0.2870 - decoder2_loss: 0.2919 - decoder1_accuracy: 0.8827 - decoder1_BER: 0.0587 - decoder2_accuracy: 0.8809 - decoder2_BER: 0.0596 - val_loss: 0.2886 - val_decoder1_loss: 0.2879 - val_decoder2_loss: 0.2893 - val_decoder1_accuracy: 0.8827 - val_decoder1_BER: 0.0586 - val_decoder2_accuracy: 0.8821 - val_decoder2_BER: 0.0590\nEpoch 596/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2868 - decoder1_loss: 0.2867 - decoder2_loss: 0.2870 - decoder1_accuracy: 0.8828 - decoder1_BER: 0.0586 - decoder2_accuracy: 0.8824 - decoder2_BER: 0.0588 - val_loss: 0.2887 - val_decoder1_loss: 0.2879 - val_decoder2_loss: 0.2896 - val_decoder1_accuracy: 0.8822 - val_decoder1_BER: 0.0589 - val_decoder2_accuracy: 0.8817 - val_decoder2_BER: 0.0592\nEpoch 597/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2884 - decoder1_loss: 0.2881 - decoder2_loss: 0.2886 - decoder1_accuracy: 0.8826 - decoder1_BER: 0.0587 - decoder2_accuracy: 0.8823 - decoder2_BER: 0.0588 - val_loss: 0.2886 - val_decoder1_loss: 0.2880 - val_decoder2_loss: 0.2891 - val_decoder1_accuracy: 0.8817 - val_decoder1_BER: 0.0591 - val_decoder2_accuracy: 0.8821 - val_decoder2_BER: 0.0589\nEpoch 598/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2884 - decoder1_loss: 0.2889 - decoder2_loss: 0.2879 - decoder1_accuracy: 0.8819 - decoder1_BER: 0.0591 - decoder2_accuracy: 0.8822 - decoder2_BER: 0.0589 - val_loss: 0.2874 - val_decoder1_loss: 0.2881 - val_decoder2_loss: 0.2867 - val_decoder1_accuracy: 0.8817 - val_decoder1_BER: 0.0591 - val_decoder2_accuracy: 0.8826 - val_decoder2_BER: 0.0587\nEpoch 599/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2881 - decoder1_loss: 0.2868 - decoder2_loss: 0.2893 - decoder1_accuracy: 0.8829 - decoder1_BER: 0.0585 - decoder2_accuracy: 0.8821 - decoder2_BER: 0.0590 - val_loss: 0.2880 - val_decoder1_loss: 0.2865 - val_decoder2_loss: 0.2895 - val_decoder1_accuracy: 0.8836 - val_decoder1_BER: 0.0582 - val_decoder2_accuracy: 0.8825 - val_decoder2_BER: 0.0588\nEpoch 600/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2874 - decoder1_loss: 0.2864 - decoder2_loss: 0.2884 - decoder1_accuracy: 0.8838 - decoder1_BER: 0.0581 - decoder2_accuracy: 0.8828 - decoder2_BER: 0.0586 - val_loss: 0.2897 - val_decoder1_loss: 0.2902 - val_decoder2_loss: 0.2892 - val_decoder1_accuracy: 0.8818 - val_decoder1_BER: 0.0591 - val_decoder2_accuracy: 0.8816 - val_decoder2_BER: 0.0592\nEpoch 601/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2876 - decoder1_loss: 0.2857 - decoder2_loss: 0.2895 - decoder1_accuracy: 0.8833 - decoder1_BER: 0.0583 - decoder2_accuracy: 0.8820 - decoder2_BER: 0.0590 - val_loss: 0.2887 - val_decoder1_loss: 0.2911 - val_decoder2_loss: 0.2862 - val_decoder1_accuracy: 0.8806 - val_decoder1_BER: 0.0597 - val_decoder2_accuracy: 0.8842 - val_decoder2_BER: 0.0579\nEpoch 602/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2886 - decoder1_loss: 0.2890 - decoder2_loss: 0.2882 - decoder1_accuracy: 0.8816 - decoder1_BER: 0.0592 - decoder2_accuracy: 0.8822 - decoder2_BER: 0.0589 - val_loss: 0.2870 - val_decoder1_loss: 0.2865 - val_decoder2_loss: 0.2874 - val_decoder1_accuracy: 0.8821 - val_decoder1_BER: 0.0589 - val_decoder2_accuracy: 0.8829 - val_decoder2_BER: 0.0586\nEpoch 603/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2880 - decoder1_loss: 0.2873 - decoder2_loss: 0.2887 - decoder1_accuracy: 0.8826 - decoder1_BER: 0.0587 - decoder2_accuracy: 0.8818 - decoder2_BER: 0.0591 - val_loss: 0.2875 - val_decoder1_loss: 0.2876 - val_decoder2_loss: 0.2875 - val_decoder1_accuracy: 0.8832 - val_decoder1_BER: 0.0584 - val_decoder2_accuracy: 0.8827 - val_decoder2_BER: 0.0586\nEpoch 604/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2886 - decoder1_loss: 0.2884 - decoder2_loss: 0.2889 - decoder1_accuracy: 0.8820 - decoder1_BER: 0.0590 - decoder2_accuracy: 0.8823 - decoder2_BER: 0.0589 - val_loss: 0.2869 - val_decoder1_loss: 0.2860 - val_decoder2_loss: 0.2878 - val_decoder1_accuracy: 0.8835 - val_decoder1_BER: 0.0583 - val_decoder2_accuracy: 0.8820 - val_decoder2_BER: 0.0590\nEpoch 605/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2898 - decoder1_loss: 0.2898 - decoder2_loss: 0.2898 - decoder1_accuracy: 0.8818 - decoder1_BER: 0.0591 - decoder2_accuracy: 0.8818 - decoder2_BER: 0.0591 - val_loss: 0.2889 - val_decoder1_loss: 0.2899 - val_decoder2_loss: 0.2880 - val_decoder1_accuracy: 0.8817 - val_decoder1_BER: 0.0591 - val_decoder2_accuracy: 0.8830 - val_decoder2_BER: 0.0585\nEpoch 606/2000\n200000/200000 [==============================] - 0s 2us/step - loss: 0.2878 - decoder1_loss: 0.2883 - decoder2_loss: 0.2873 - decoder1_accuracy: 0.8819 - decoder1_BER: 0.0591 - decoder2_accuracy: 0.8826 - decoder2_BER: 0.0587 - val_loss: 0.2888 - val_decoder1_loss: 0.2885 - val_decoder2_loss: 0.2891 - val_decoder1_accuracy: 0.8815 - val_decoder1_BER: 0.0592 - val_decoder2_accuracy: 0.8826 - val_decoder2_BER: 0.0587\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.callbacks.History at 0x7f64581fe690>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "train_datas = generate_train_datas(k=2)\n",
    "\n",
    "model.fit(x=train_datas, y=train_datas, validation_split=.5, batch_size=40000,\n",
    "    epochs=2000, callbacks=[\n",
    "    EarlyStopping(patience=100, restore_best_weights=True, monitor=\"loss\", mode=\"min\"),\n",
    "    ReduceLROnPlateau(monitor=\"loss\", factor=.5, patience=20),\n",
    "    AlphaCallback(alpha),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 380.482812 248.518125\" width=\"380.482812pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 248.518125 \nL 380.482812 248.518125 \nL 380.482812 0 \nL -0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 38.482813 224.64 \nL 373.282813 224.64 \nL 373.282813 7.2 \nL 38.482813 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"PathCollection_1\">\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"m26586327b0\" style=\"stroke:#1f77b4;\"/>\n    </defs>\n    <g clip-path=\"url(#pe5de1b444b)\">\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"84.121171\" xlink:href=\"#m26586327b0\" y=\"17.083636\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"358.064631\" xlink:href=\"#m26586327b0\" y=\"46.015186\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"178.836588\" xlink:href=\"#m26586327b0\" y=\"28.373819\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"260.191296\" xlink:href=\"#m26586327b0\" y=\"35.653035\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"57.846133\" xlink:href=\"#m26586327b0\" y=\"136.985645\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"329.862146\" xlink:href=\"#m26586327b0\" y=\"154.773072\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"153.922849\" xlink:href=\"#m26586327b0\" y=\"142.148285\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"234.912832\" xlink:href=\"#m26586327b0\" y=\"148.545607\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"53.700994\" xlink:href=\"#m26586327b0\" y=\"200.645201\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"321.644329\" xlink:href=\"#m26586327b0\" y=\"214.756364\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"147.592124\" xlink:href=\"#m26586327b0\" y=\"206.020795\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"227.811755\" xlink:href=\"#m26586327b0\" y=\"210.278819\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"64.232336\" xlink:href=\"#m26586327b0\" y=\"81.559534\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"336.325466\" xlink:href=\"#m26586327b0\" y=\"105.384162\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"162.052047\" xlink:href=\"#m26586327b0\" y=\"89.588163\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"242.959291\" xlink:href=\"#m26586327b0\" y=\"96.195248\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m3f6bee9316\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"48.753124\" xlink:href=\"#m3f6bee9316\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- −1.5 -->\n      <defs>\n       <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(36.611717 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"99.36347\" xlink:href=\"#m3f6bee9316\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- −1.0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(87.222064 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"149.973817\" xlink:href=\"#m3f6bee9316\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- −0.5 -->\n      <g transform=\"translate(137.832411 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"200.584164\" xlink:href=\"#m3f6bee9316\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0.0 -->\n      <g transform=\"translate(192.632602 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"251.194511\" xlink:href=\"#m3f6bee9316\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.5 -->\n      <g transform=\"translate(243.242948 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"301.804858\" xlink:href=\"#m3f6bee9316\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 1.0 -->\n      <g transform=\"translate(293.853295 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"352.415205\" xlink:href=\"#m3f6bee9316\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 1.5 -->\n      <g transform=\"translate(344.463642 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mb0947f985a\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#mb0947f985a\" y=\"218.245129\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- −1.5 -->\n      <g transform=\"translate(7.2 222.044348)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#mb0947f985a\" y=\"185.376957\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- −1.0 -->\n      <g transform=\"translate(7.2 189.176176)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#mb0947f985a\" y=\"152.508785\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- −0.5 -->\n      <g transform=\"translate(7.2 156.308004)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#mb0947f985a\" y=\"119.640613\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.0 -->\n      <g transform=\"translate(15.579688 123.439831)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#mb0947f985a\" y=\"86.772441\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.5 -->\n      <g transform=\"translate(15.579688 90.571659)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#mb0947f985a\" y=\"53.904268\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.0 -->\n      <g transform=\"translate(15.579688 57.703487)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#mb0947f985a\" y=\"21.036096\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 1.5 -->\n      <g transform=\"translate(15.579688 24.835315)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 38.482813 224.64 \nL 38.482813 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 373.282813 224.64 \nL 373.282813 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 38.482812 224.64 \nL 373.282812 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 38.482812 7.2 \nL 373.282812 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pe5de1b444b\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"38.482813\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": []
  }
 ]
}