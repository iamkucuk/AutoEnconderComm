{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing libs\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, GaussianNoise, Lambda\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "import random as rn\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def frange(x, y, jump):\n",
    "  while x < y:\n",
    "    yield x\n",
    "    x += jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: 16 k: 4 n:  7 R:  0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "# defining parameters\n",
    "k = 8\n",
    "M = 2**k\n",
    "# k = np.log2(M)\n",
    "# k = int(k)\n",
    "n_channel = 8\n",
    "R = k/n_channel\n",
    "print ('M:',M,'k:',k, \"n: \", n_channel, \"R: \", R)\n",
    "\n",
    "EbNodB_range = list(frange(-4,8,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=24\n",
    "tf.set_random_seed(seed)\n",
    "rn.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating data of size N\n",
    "N = 10000\n",
    "label = np.random.randint(M,size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating one hot encoded vectors\n",
    "data = []\n",
    "for i in label:\n",
    "    temp = np.zeros(M)\n",
    "    temp[i] = 1\n",
    "    data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "7 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "9 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "9 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "7 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "10 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "2 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "5 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "13 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "temp_check = [17,23,45,67,89,96,72,250,350]\n",
    "for i in temp_check:\n",
    "    print(label[i],data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print (int(k/R))\n",
    "input_signal = Input(shape=(M,))\n",
    "encoded = Dense(M, activation='relu')(input_signal)\n",
    "encoded1 = Dense(n_channel, activation='linear')(encoded)\n",
    "encoded2 = BatchNormalization(center=False, scale=False)(encoded1)\n",
    "# encoded2 = Lambda(lambda x: 1.0/np.sqrt(2)*K.l2_normalize(x,axis=-1))(encoded2)\n",
    "\n",
    "EbNo_train = 5.01187 #  coverted 7 db of EbNo\n",
    "encoded3 = GaussianNoise(np.sqrt(1/(2*R*EbNo_train)))(encoded2)\n",
    "\n",
    "decoded = Dense(M, activation='relu')(encoded3)\n",
    "decoded1 = Dense(M, activation='softmax')(decoded)\n",
    "\n",
    "autoencoder = Model(input_signal, decoded1)\n",
    "#sgd = SGD(lr=0.001)\n",
    "autoencoder.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_63\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_46 (InputLayer)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 7)                 119       \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 7)                 14        \n",
      "_________________________________________________________________\n",
      "gaussian_noise_23 (GaussianN (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 16)                128       \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 16)                272       \n",
      "=================================================================\n",
      "Total params: 805\n",
      "Trainable params: 791\n",
      "Non-trainable params: 14\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (autoencoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_val = 1500\n",
    "val_label = np.random.randint(M,size=N_val)\n",
    "val_data = []\n",
    "for i in val_label:\n",
    "    temp = np.zeros(M)\n",
    "    temp[i] = 1\n",
    "    val_data.append(temp)\n",
    "val_data = np.array(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1500 samples\n",
      "Epoch 1/1000\n",
      "10000/10000 [==============================] - 1s 96us/step - loss: 2.6537 - val_loss: 2.6701\n",
      "Epoch 2/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 2.1086 - val_loss: 2.5237\n",
      "Epoch 3/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 1.7393 - val_loss: 2.3435\n",
      "Epoch 4/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 1.4429 - val_loss: 2.1220\n",
      "Epoch 5/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 1.1743 - val_loss: 1.8586\n",
      "Epoch 6/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.9354 - val_loss: 1.5595\n",
      "Epoch 7/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.7361 - val_loss: 1.2478\n",
      "Epoch 8/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.5802 - val_loss: 0.9463\n",
      "Epoch 9/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.4588 - val_loss: 0.6829\n",
      "Epoch 10/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.3679 - val_loss: 0.4697\n",
      "Epoch 11/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.2949 - val_loss: 0.3145\n",
      "Epoch 12/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.2405 - val_loss: 0.2080\n",
      "Epoch 13/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.2036 - val_loss: 0.1415\n",
      "Epoch 14/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.1731 - val_loss: 0.0993\n",
      "Epoch 15/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.1497 - val_loss: 0.0725\n",
      "Epoch 16/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.1289 - val_loss: 0.0549\n",
      "Epoch 17/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.1154 - val_loss: 0.0430\n",
      "Epoch 18/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.1028 - val_loss: 0.0343\n",
      "Epoch 19/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0911 - val_loss: 0.0281\n",
      "Epoch 20/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0844 - val_loss: 0.0234\n",
      "Epoch 21/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0762 - val_loss: 0.0202\n",
      "Epoch 22/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0682 - val_loss: 0.0173\n",
      "Epoch 23/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0636 - val_loss: 0.0150\n",
      "Epoch 24/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0615 - val_loss: 0.0131\n",
      "Epoch 25/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0558 - val_loss: 0.0115\n",
      "Epoch 26/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0511 - val_loss: 0.0101\n",
      "Epoch 27/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0473 - val_loss: 0.0089\n",
      "Epoch 28/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0458 - val_loss: 0.0081\n",
      "Epoch 29/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0428 - val_loss: 0.0073\n",
      "Epoch 30/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0407 - val_loss: 0.0065\n",
      "Epoch 31/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0397 - val_loss: 0.0059\n",
      "Epoch 32/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0353 - val_loss: 0.0053\n",
      "Epoch 33/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0342 - val_loss: 0.0048\n",
      "Epoch 34/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0328 - val_loss: 0.0044\n",
      "Epoch 35/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0295 - val_loss: 0.0040\n",
      "Epoch 36/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0301 - val_loss: 0.0037\n",
      "Epoch 37/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0275 - val_loss: 0.0034\n",
      "Epoch 38/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0266 - val_loss: 0.0031\n",
      "Epoch 39/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0250 - val_loss: 0.0029\n",
      "Epoch 40/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0257 - val_loss: 0.0026\n",
      "Epoch 41/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0258 - val_loss: 0.0024\n",
      "Epoch 42/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0229 - val_loss: 0.0022\n",
      "Epoch 43/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0228 - val_loss: 0.0021\n",
      "Epoch 44/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0219 - val_loss: 0.0019\n",
      "Epoch 45/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0203 - val_loss: 0.0018\n",
      "Epoch 46/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0190 - val_loss: 0.0016\n",
      "Epoch 47/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0194 - val_loss: 0.0015\n",
      "Epoch 48/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0183 - val_loss: 0.0014\n",
      "Epoch 49/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0177 - val_loss: 0.0013\n",
      "Epoch 50/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0178 - val_loss: 0.0013\n",
      "Epoch 51/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0170 - val_loss: 0.0012\n",
      "Epoch 52/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0161 - val_loss: 0.0011\n",
      "Epoch 53/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0158 - val_loss: 0.0010\n",
      "Epoch 54/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0150 - val_loss: 9.4281e-04\n",
      "Epoch 55/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0147 - val_loss: 8.9303e-04\n",
      "Epoch 56/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0163 - val_loss: 8.3616e-04\n",
      "Epoch 57/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0146 - val_loss: 7.7946e-04\n",
      "Epoch 58/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0141 - val_loss: 7.2839e-04\n",
      "Epoch 59/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0136 - val_loss: 6.9345e-04\n",
      "Epoch 60/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0136 - val_loss: 6.4573e-04\n",
      "Epoch 61/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0123 - val_loss: 6.0956e-04\n",
      "Epoch 62/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0119 - val_loss: 5.9154e-04\n",
      "Epoch 63/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0125 - val_loss: 5.4443e-04\n",
      "Epoch 64/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0126 - val_loss: 5.0056e-04\n",
      "Epoch 65/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0132 - val_loss: 4.8946e-04\n",
      "Epoch 66/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0115 - val_loss: 4.5678e-04\n",
      "Epoch 67/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0123 - val_loss: 4.3201e-04\n",
      "Epoch 68/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0111 - val_loss: 4.0747e-04\n",
      "Epoch 69/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0118 - val_loss: 3.8163e-04\n",
      "Epoch 70/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0107 - val_loss: 3.6343e-04\n",
      "Epoch 71/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0113 - val_loss: 3.4631e-04\n",
      "Epoch 72/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0094 - val_loss: 3.3267e-04\n",
      "Epoch 73/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0105 - val_loss: 3.1221e-04\n",
      "Epoch 74/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0100 - val_loss: 2.9206e-04\n",
      "Epoch 75/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0090 - val_loss: 2.8070e-04\n",
      "Epoch 76/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0103 - val_loss: 2.7594e-04\n",
      "Epoch 77/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0095 - val_loss: 2.5532e-04\n",
      "Epoch 78/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0102 - val_loss: 2.3810e-04\n",
      "Epoch 79/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0094 - val_loss: 2.2339e-04\n",
      "Epoch 80/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 2.1056e-04\n",
      "Epoch 81/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0087 - val_loss: 1.9604e-04\n",
      "Epoch 82/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 1.9432e-04\n",
      "Epoch 83/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0088 - val_loss: 1.9638e-04\n",
      "Epoch 84/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0085 - val_loss: 1.7518e-04\n",
      "Epoch 85/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0082 - val_loss: 1.6929e-04\n",
      "Epoch 86/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0074 - val_loss: 1.5933e-04\n",
      "Epoch 87/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0075 - val_loss: 1.5328e-04\n",
      "Epoch 88/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0083 - val_loss: 1.4641e-04\n",
      "Epoch 89/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0092 - val_loss: 1.3789e-04\n",
      "Epoch 90/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0076 - val_loss: 1.2781e-04\n",
      "Epoch 91/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0069 - val_loss: 1.2581e-04\n",
      "Epoch 92/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0091 - val_loss: 1.1686e-04\n",
      "Epoch 93/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0068 - val_loss: 1.0823e-04\n",
      "Epoch 94/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0071 - val_loss: 1.0387e-04\n",
      "Epoch 95/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0071 - val_loss: 1.0074e-04\n",
      "Epoch 96/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0078 - val_loss: 1.0414e-04\n",
      "Epoch 97/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0061 - val_loss: 9.2502e-05\n",
      "Epoch 98/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0072 - val_loss: 9.6562e-05\n",
      "Epoch 99/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0069 - val_loss: 8.5955e-05\n",
      "Epoch 100/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0073 - val_loss: 8.3540e-05\n",
      "Epoch 101/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0071 - val_loss: 7.9459e-05\n",
      "Epoch 102/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0058 - val_loss: 7.7704e-05\n",
      "Epoch 103/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0061 - val_loss: 7.4571e-05\n",
      "Epoch 104/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0063 - val_loss: 6.7922e-05\n",
      "Epoch 105/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0065 - val_loss: 6.3268e-05\n",
      "Epoch 106/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0063 - val_loss: 6.2498e-05\n",
      "Epoch 107/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0070 - val_loss: 6.1239e-05\n",
      "Epoch 108/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0061 - val_loss: 5.9854e-05\n",
      "Epoch 109/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0061 - val_loss: 5.3619e-05\n",
      "Epoch 110/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0061 - val_loss: 5.4583e-05\n",
      "Epoch 111/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0052 - val_loss: 5.1538e-05\n",
      "Epoch 112/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0056 - val_loss: 5.0027e-05\n",
      "Epoch 113/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0056 - val_loss: 4.6217e-05\n",
      "Epoch 114/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0057 - val_loss: 4.3331e-05\n",
      "Epoch 115/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0069 - val_loss: 4.2726e-05\n",
      "Epoch 116/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0067 - val_loss: 4.1506e-05\n",
      "Epoch 117/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0057 - val_loss: 4.0145e-05\n",
      "Epoch 118/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0063 - val_loss: 3.9965e-05\n",
      "Epoch 119/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0051 - val_loss: 3.5614e-05\n",
      "Epoch 120/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 3.5785e-05\n",
      "Epoch 121/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0052 - val_loss: 3.3288e-05\n",
      "Epoch 122/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0042 - val_loss: 3.2981e-05\n",
      "Epoch 123/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0050 - val_loss: 3.1881e-05\n",
      "Epoch 124/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0046 - val_loss: 2.9792e-05\n",
      "Epoch 125/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 2.9888e-05\n",
      "Epoch 126/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0042 - val_loss: 2.6978e-05\n",
      "Epoch 127/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0045 - val_loss: 2.7098e-05\n",
      "Epoch 128/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0052 - val_loss: 2.6059e-05\n",
      "Epoch 129/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0049 - val_loss: 2.4767e-05\n",
      "Epoch 130/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0052 - val_loss: 2.3625e-05\n",
      "Epoch 131/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0040 - val_loss: 2.1419e-05\n",
      "Epoch 132/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0054 - val_loss: 2.0787e-05\n",
      "Epoch 133/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0050 - val_loss: 2.0432e-05\n",
      "Epoch 134/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0050 - val_loss: 1.9043e-05\n",
      "Epoch 135/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0041 - val_loss: 1.8824e-05\n",
      "Epoch 136/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0043 - val_loss: 1.8474e-05\n",
      "Epoch 137/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0041 - val_loss: 1.7223e-05\n",
      "Epoch 138/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0053 - val_loss: 1.6690e-05\n",
      "Epoch 139/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0046 - val_loss: 1.6267e-05\n",
      "Epoch 140/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0046 - val_loss: 1.5917e-05\n",
      "Epoch 141/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0037 - val_loss: 1.4822e-05\n",
      "Epoch 142/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0045 - val_loss: 1.4150e-05\n",
      "Epoch 143/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0044 - val_loss: 1.4312e-05\n",
      "Epoch 144/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0044 - val_loss: 1.3558e-05\n",
      "Epoch 145/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0044 - val_loss: 1.2240e-05\n",
      "Epoch 146/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0055 - val_loss: 1.3064e-05\n",
      "Epoch 147/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0036 - val_loss: 1.2926e-05\n",
      "Epoch 148/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0045 - val_loss: 1.2074e-05\n",
      "Epoch 149/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0043 - val_loss: 1.1249e-05\n",
      "Epoch 150/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0036 - val_loss: 1.0323e-05\n",
      "Epoch 151/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0038 - val_loss: 9.8069e-06\n",
      "Epoch 152/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0032 - val_loss: 1.0417e-05\n",
      "Epoch 153/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0034 - val_loss: 9.7888e-06\n",
      "Epoch 154/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0038 - val_loss: 9.4131e-06\n",
      "Epoch 155/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0039 - val_loss: 8.5714e-06\n",
      "Epoch 156/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0036 - val_loss: 7.8593e-06\n",
      "Epoch 157/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0042 - val_loss: 7.9822e-06\n",
      "Epoch 158/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0047 - val_loss: 8.0669e-06\n",
      "Epoch 159/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0034 - val_loss: 8.5708e-06\n",
      "Epoch 160/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0046 - val_loss: 8.2287e-06\n",
      "Epoch 161/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0048 - val_loss: 7.6905e-06\n",
      "Epoch 162/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0043 - val_loss: 8.4859e-06\n",
      "Epoch 163/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0033 - val_loss: 7.7665e-06\n",
      "Epoch 164/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0037 - val_loss: 6.8915e-06\n",
      "Epoch 165/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0035 - val_loss: 8.3437e-06\n",
      "Epoch 166/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0046 - val_loss: 8.0215e-06\n",
      "Epoch 167/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0034 - val_loss: 6.1756e-06\n",
      "Epoch 168/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0050 - val_loss: 5.7802e-06\n",
      "Epoch 169/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0034 - val_loss: 6.1280e-06\n",
      "Epoch 170/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0038 - val_loss: 5.8819e-06\n",
      "Epoch 171/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0038 - val_loss: 5.8138e-06\n",
      "Epoch 172/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0041 - val_loss: 6.1119e-06\n",
      "Epoch 173/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0037 - val_loss: 5.1524e-06\n",
      "Epoch 174/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0028 - val_loss: 5.0460e-06\n",
      "Epoch 175/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0036 - val_loss: 4.8141e-06\n",
      "Epoch 176/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0041 - val_loss: 4.4780e-06\n",
      "Epoch 177/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0030 - val_loss: 4.3781e-06\n",
      "Epoch 178/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0034 - val_loss: 4.1604e-06\n",
      "Epoch 179/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0037 - val_loss: 4.1247e-06\n",
      "Epoch 180/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0032 - val_loss: 3.9820e-06\n",
      "Epoch 181/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0043 - val_loss: 4.0676e-06\n",
      "Epoch 182/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0038 - val_loss: 3.3450e-06\n",
      "Epoch 183/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0044 - val_loss: 3.0130e-06\n",
      "Epoch 184/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0035 - val_loss: 2.9281e-06\n",
      "Epoch 185/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0046 - val_loss: 3.3441e-06\n",
      "Epoch 186/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0041 - val_loss: 4.0546e-06\n",
      "Epoch 187/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0035 - val_loss: 4.5692e-06\n",
      "Epoch 188/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0036 - val_loss: 3.7783e-06\n",
      "Epoch 189/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0024 - val_loss: 3.4749e-06\n",
      "Epoch 190/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0037 - val_loss: 3.2120e-06\n",
      "Epoch 191/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0036 - val_loss: 2.8872e-06\n",
      "Epoch 192/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0034 - val_loss: 3.0028e-06\n",
      "Epoch 193/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0036 - val_loss: 2.5932e-06\n",
      "Epoch 194/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0030 - val_loss: 2.6646e-06\n",
      "Epoch 195/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0036 - val_loss: 3.0613e-06\n",
      "Epoch 196/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0027 - val_loss: 3.1561e-06\n",
      "Epoch 197/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0023 - val_loss: 2.6584e-06\n",
      "Epoch 198/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0026 - val_loss: 2.7264e-06\n",
      "Epoch 199/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0026 - val_loss: 2.9689e-06\n",
      "Epoch 200/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0032 - val_loss: 2.7323e-06\n",
      "Epoch 201/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0037 - val_loss: 2.1565e-06\n",
      "Epoch 202/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0026 - val_loss: 2.4406e-06\n",
      "Epoch 203/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0031 - val_loss: 2.2000e-06\n",
      "Epoch 204/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0032 - val_loss: 2.7102e-06\n",
      "Epoch 205/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0032 - val_loss: 2.7165e-06\n",
      "Epoch 206/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0026 - val_loss: 2.1422e-06\n",
      "Epoch 207/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0040 - val_loss: 2.4141e-06\n",
      "Epoch 208/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0029 - val_loss: 2.9837e-06\n",
      "Epoch 209/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0033 - val_loss: 4.1373e-06\n",
      "Epoch 210/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0027 - val_loss: 2.9042e-06\n",
      "Epoch 211/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0023 - val_loss: 2.9417e-06\n",
      "Epoch 212/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0030 - val_loss: 3.0150e-06\n",
      "Epoch 213/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0030 - val_loss: 3.0723e-06\n",
      "Epoch 214/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0038 - val_loss: 3.1363e-06\n",
      "Epoch 215/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0021 - val_loss: 2.8204e-06\n",
      "Epoch 216/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0025 - val_loss: 1.8184e-06\n",
      "Epoch 217/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0022 - val_loss: 1.8388e-06\n",
      "Epoch 218/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0025 - val_loss: 1.7119e-06\n",
      "Epoch 219/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0028 - val_loss: 1.8455e-06\n",
      "Epoch 220/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0021 - val_loss: 1.7712e-06\n",
      "Epoch 221/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0026 - val_loss: 2.0634e-06\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0033 - val_loss: 3.0632e-06\n",
      "Epoch 223/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0017 - val_loss: 2.3645e-06\n",
      "Epoch 224/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0026 - val_loss: 3.2842e-06\n",
      "Epoch 225/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0031 - val_loss: 1.9853e-06\n",
      "Epoch 226/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0030 - val_loss: 2.0270e-06\n",
      "Epoch 227/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0019 - val_loss: 1.7742e-06\n",
      "Epoch 228/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0020 - val_loss: 2.2144e-06\n",
      "Epoch 229/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0021 - val_loss: 1.8371e-06\n",
      "Epoch 230/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0035 - val_loss: 1.8885e-06\n",
      "Epoch 231/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0043 - val_loss: 2.5724e-06\n",
      "Epoch 232/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0022 - val_loss: 2.4412e-06\n",
      "Epoch 233/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0023 - val_loss: 1.8017e-06\n",
      "Epoch 234/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0031 - val_loss: 9.2792e-07\n",
      "Epoch 235/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0023 - val_loss: 9.9126e-07\n",
      "Epoch 236/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0022 - val_loss: 1.5392e-06\n",
      "Epoch 237/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0024 - val_loss: 1.7153e-06\n",
      "Epoch 238/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0029 - val_loss: 1.5480e-06\n",
      "Epoch 239/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0034 - val_loss: 2.1048e-06\n",
      "Epoch 240/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0029 - val_loss: 1.5130e-06\n",
      "Epoch 241/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0019 - val_loss: 1.3756e-06\n",
      "Epoch 242/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0028 - val_loss: 1.0686e-06\n",
      "Epoch 243/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0027 - val_loss: 1.0765e-06\n",
      "Epoch 244/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0020 - val_loss: 1.6275e-06\n",
      "Epoch 245/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0019 - val_loss: 1.8573e-06\n",
      "Epoch 246/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0019 - val_loss: 1.1782e-06\n",
      "Epoch 247/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0027 - val_loss: 1.4175e-06\n",
      "Epoch 248/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0022 - val_loss: 1.8005e-06\n",
      "Epoch 249/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0047 - val_loss: 1.7851e-06\n",
      "Epoch 250/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0035 - val_loss: 1.4228e-06\n",
      "Epoch 251/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0034 - val_loss: 1.3774e-06\n",
      "Epoch 252/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0024 - val_loss: 1.1411e-06\n",
      "Epoch 253/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0028 - val_loss: 8.7007e-07\n",
      "Epoch 254/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0043 - val_loss: 7.7089e-07\n",
      "Epoch 255/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0030 - val_loss: 6.4588e-07\n",
      "Epoch 256/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0042 - val_loss: 7.7708e-07\n",
      "Epoch 257/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0029 - val_loss: 7.1589e-07\n",
      "Epoch 258/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0037 - val_loss: 7.4633e-07\n",
      "Epoch 259/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0030 - val_loss: 6.9952e-07\n",
      "Epoch 260/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0042 - val_loss: 8.7730e-07\n",
      "Epoch 261/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0021 - val_loss: 8.7539e-07\n",
      "Epoch 262/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0019 - val_loss: 1.1297e-06\n",
      "Epoch 263/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0019 - val_loss: 1.0355e-06\n",
      "Epoch 264/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0019 - val_loss: 9.7123e-07\n",
      "Epoch 265/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0025 - val_loss: 6.0701e-07\n",
      "Epoch 266/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0015 - val_loss: 7.2066e-07\n",
      "Epoch 267/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0023 - val_loss: 8.7674e-07\n",
      "Epoch 268/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0035 - val_loss: 1.1829e-06\n",
      "Epoch 269/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0022 - val_loss: 7.2265e-07\n",
      "Epoch 270/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0011 - val_loss: 7.2010e-07\n",
      "Epoch 271/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0020 - val_loss: 8.2270e-07\n",
      "Epoch 272/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0026 - val_loss: 1.0512e-06\n",
      "Epoch 273/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0030 - val_loss: 9.9237e-07\n",
      "Epoch 274/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0034 - val_loss: 8.5497e-07\n",
      "Epoch 275/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0018 - val_loss: 1.1465e-06\n",
      "Epoch 276/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0038 - val_loss: 8.3883e-07\n",
      "Epoch 277/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0028 - val_loss: 1.0076e-06\n",
      "Epoch 278/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0024 - val_loss: 6.8188e-07\n",
      "Epoch 279/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0017 - val_loss: 8.2103e-07\n",
      "Epoch 280/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0027 - val_loss: 6.1989e-07\n",
      "Epoch 281/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0025 - val_loss: 6.8680e-07\n",
      "Epoch 282/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0024 - val_loss: 6.7369e-07\n",
      "Epoch 283/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0018 - val_loss: 1.0145e-06\n",
      "Epoch 284/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0021 - val_loss: 1.2434e-06\n",
      "Epoch 285/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0021 - val_loss: 1.0625e-06\n",
      "Epoch 286/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0019 - val_loss: 7.8551e-07\n",
      "Epoch 287/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0021 - val_loss: 9.0575e-07\n",
      "Epoch 288/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0024 - val_loss: 9.9897e-07\n",
      "Epoch 289/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0013 - val_loss: 1.2319e-06\n",
      "Epoch 290/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0025 - val_loss: 1.3784e-06\n",
      "Epoch 291/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0025 - val_loss: 1.1949e-06\n",
      "Epoch 292/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0023 - val_loss: 7.0810e-07\n",
      "Epoch 293/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0026 - val_loss: 5.5996e-07\n",
      "Epoch 294/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0022 - val_loss: 6.7186e-07\n",
      "Epoch 295/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0018 - val_loss: 7.2471e-07\n",
      "Epoch 296/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0021 - val_loss: 6.1560e-07\n",
      "Epoch 297/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0016 - val_loss: 6.3610e-07\n",
      "Epoch 298/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0016 - val_loss: 7.7088e-07\n",
      "Epoch 299/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0018 - val_loss: 1.0853e-06\n",
      "Epoch 300/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0027 - val_loss: 9.8427e-07\n",
      "Epoch 301/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0019 - val_loss: 9.9046e-07\n",
      "Epoch 302/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0025 - val_loss: 1.0815e-06\n",
      "Epoch 303/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0027 - val_loss: 1.0379e-06\n",
      "Epoch 304/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0031 - val_loss: 5.0839e-07\n",
      "Epoch 305/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0030 - val_loss: 4.9281e-07\n",
      "Epoch 306/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0035 - val_loss: 5.5512e-07\n",
      "Epoch 307/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0027 - val_loss: 5.7268e-07\n",
      "Epoch 308/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0017 - val_loss: 5.0076e-07\n",
      "Epoch 309/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0040 - val_loss: 5.9899e-07\n",
      "Epoch 310/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0023 - val_loss: 4.3940e-07\n",
      "Epoch 311/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0020 - val_loss: 4.3257e-07\n",
      "Epoch 312/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0024 - val_loss: 3.8918e-07\n",
      "Epoch 313/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0016 - val_loss: 4.5625e-07\n",
      "Epoch 314/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0023 - val_loss: 4.5355e-07\n",
      "Epoch 315/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0016 - val_loss: 5.2508e-07\n",
      "Epoch 316/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0018 - val_loss: 5.7522e-07\n",
      "Epoch 317/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0024 - val_loss: 5.1125e-07\n",
      "Epoch 318/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0019 - val_loss: 5.3485e-07\n",
      "Epoch 319/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0023 - val_loss: 4.9702e-07\n",
      "Epoch 320/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0013 - val_loss: 3.9355e-07\n",
      "Epoch 321/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0018 - val_loss: 4.9146e-07\n",
      "Epoch 322/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0018 - val_loss: 6.4476e-07\n",
      "Epoch 323/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0013 - val_loss: 5.3008e-07\n",
      "Epoch 324/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0015 - val_loss: 6.0296e-07\n",
      "Epoch 325/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0024 - val_loss: 6.2044e-07\n",
      "Epoch 326/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0017 - val_loss: 6.7170e-07\n",
      "Epoch 327/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0017 - val_loss: 7.9560e-07\n",
      "Epoch 328/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0024 - val_loss: 1.3990e-06\n",
      "Epoch 329/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0027 - val_loss: 7.8487e-07\n",
      "Epoch 330/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0028 - val_loss: 4.1556e-07\n",
      "Epoch 331/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0023 - val_loss: 4.7668e-07\n",
      "Epoch 332/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0024 - val_loss: 4.5705e-07\n",
      "Epoch 333/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0032 - val_loss: 5.2047e-07\n",
      "Epoch 334/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0024 - val_loss: 7.6437e-07\n",
      "Epoch 335/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0012 - val_loss: 8.9041e-07\n",
      "Epoch 336/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0026 - val_loss: 5.2881e-07\n",
      "Epoch 337/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0023 - val_loss: 7.9512e-07\n",
      "Epoch 338/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0042 - val_loss: 6.6336e-07\n",
      "Epoch 339/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0024 - val_loss: 5.8826e-07\n",
      "Epoch 340/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0025 - val_loss: 9.9134e-07\n",
      "Epoch 341/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0024 - val_loss: 1.0779e-06\n",
      "Epoch 342/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0020 - val_loss: 8.2484e-07\n",
      "Epoch 343/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0017 - val_loss: 8.5520e-07\n",
      "Epoch 344/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0023 - val_loss: 7.2725e-07\n",
      "Epoch 345/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0023 - val_loss: 3.9744e-07\n",
      "Epoch 346/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0022 - val_loss: 5.3978e-07\n",
      "Epoch 347/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0022 - val_loss: 6.2259e-07\n",
      "Epoch 348/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0020 - val_loss: 7.0834e-07\n",
      "Epoch 349/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0013 - val_loss: 7.4013e-07\n",
      "Epoch 350/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0019 - val_loss: 4.9599e-07\n",
      "Epoch 351/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0019 - val_loss: 4.7278e-07\n",
      "Epoch 352/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0014 - val_loss: 5.5901e-07\n",
      "Epoch 353/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0019 - val_loss: 6.0955e-07\n",
      "Epoch 354/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0022 - val_loss: 5.4908e-07\n",
      "Epoch 355/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0017 - val_loss: 7.0413e-07\n",
      "Epoch 356/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0021 - val_loss: 3.5795e-07\n",
      "Epoch 357/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0025 - val_loss: 4.3591e-07\n",
      "Epoch 358/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0037 - val_loss: 4.9051e-07\n",
      "Epoch 359/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0023 - val_loss: 5.9064e-07\n",
      "Epoch 360/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0013 - val_loss: 3.5508e-07\n",
      "Epoch 361/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0012 - val_loss: 4.0007e-07\n",
      "Epoch 362/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0016 - val_loss: 4.5442e-07\n",
      "Epoch 363/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0020 - val_loss: 4.9909e-07\n",
      "Epoch 364/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0020 - val_loss: 3.8600e-07\n",
      "Epoch 365/1000\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.0013 - val_loss: 5.2404e-07\n",
      "Epoch 366/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0017 - val_loss: 5.9056e-07\n",
      "Epoch 367/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0032 - val_loss: 5.1061e-07\n",
      "Epoch 368/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0019 - val_loss: 2.2952e-07\n",
      "Epoch 369/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0014 - val_loss: 2.0790e-07\n",
      "Epoch 370/1000\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.0018 - val_loss: 2.1648e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x232c3d57fd0>"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(patience=100, restore_best_weights=True, monitor=\"loss\")\n",
    "autoencoder.fit(data, data,\n",
    "                epochs=1000,\n",
    "                batch_size=300,\n",
    "                validation_data=(val_data, val_data),\n",
    "               callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "#autoencoder.save('4_7_symbol_autoencoder_v_best.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoencoder_loaded = load_model('4_7_symbol_autoencoder_v_best.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(input_signal, encoded2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = Input(shape=(n_channel,))\n",
    "\n",
    "deco = autoencoder.layers[-2](encoded_input)\n",
    "deco = autoencoder.layers[-1](deco)\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, deco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 45000\n",
    "test_label = np.random.randint(M,size=N)\n",
    "test_data = []\n",
    "\n",
    "for i in test_label:\n",
    "    temp = np.zeros(M)\n",
    "    temp[i] = 1\n",
    "    test_data.append(temp)\n",
    "    \n",
    "test_data = np.array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 6\n"
     ]
    }
   ],
   "source": [
    "temp_test = 6\n",
    "print (test_data[temp_test][test_label[temp_test]],test_label[temp_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x232c3cf16a0>"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR: -4 BER: 0.5205333333333333\n",
      "SNR: -3.5 BER: 0.48602222222222224\n",
      "SNR: -3.0 BER: 0.44593333333333335\n",
      "SNR: -2.5 BER: 0.4081111111111111\n",
      "SNR: -2.0 BER: 0.3688888888888889\n",
      "SNR: -1.5 BER: 0.33326666666666666\n",
      "SNR: -1.0 BER: 0.29055555555555557\n",
      "SNR: -0.5 BER: 0.2576888888888889\n",
      "SNR: 0.0 BER: 0.21613333333333334\n",
      "SNR: 0.5 BER: 0.1794\n",
      "SNR: 1.0 BER: 0.1449777777777778\n",
      "SNR: 1.5 BER: 0.1158\n",
      "SNR: 2.0 BER: 0.09113333333333333\n",
      "SNR: 2.5 BER: 0.06764444444444444\n",
      "SNR: 3.0 BER: 0.04971111111111111\n",
      "SNR: 3.5 BER: 0.032577777777777775\n",
      "SNR: 4.0 BER: 0.0202\n",
      "SNR: 4.5 BER: 0.014177777777777777\n",
      "SNR: 5.0 BER: 0.008155555555555555\n",
      "SNR: 5.5 BER: 0.004288888888888889\n",
      "SNR: 6.0 BER: 0.0024\n",
      "SNR: 6.5 BER: 0.0014\n",
      "SNR: 7.0 BER: 0.00046666666666666666\n",
      "SNR: 7.5 BER: 0.0002666666666666667\n"
     ]
    }
   ],
   "source": [
    "ber = [None]*len(EbNodB_range)\n",
    "for n in range(0,len(EbNodB_range)):\n",
    "    EbNo=10.0**(EbNodB_range[n]/10.0)\n",
    "    noise_std = np.sqrt(1/(2*R*EbNo))\n",
    "    noise_mean = 0\n",
    "    no_errors = 0\n",
    "    nn = N\n",
    "    noise = noise_std * np.random.randn(nn,n_channel)\n",
    "    encoded_signal = encoder.predict(test_data) \n",
    "    final_signal = encoded_signal + noise\n",
    "    pred_final_signal =  decoder.predict(final_signal)\n",
    "    pred_output = np.argmax(pred_final_signal,axis=1)\n",
    "    no_errors = (pred_output != test_label)\n",
    "    no_errors =  no_errors.astype(int).sum()\n",
    "    ber[n] = no_errors / nn \n",
    "    print ('SNR:',EbNodB_range[n],'BER:',ber[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(EbNodB_range, ber, 'bo',label='Autoencoder({}, {})'.format(n_channel, k))\n",
    "#plt.plot(list(EbNodB_range), ber_theory, 'ro-',label='BPSK BER')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('SNR Range')\n",
    "plt.ylabel('Block Error Rate')\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right',ncol = 1)\n",
    "plt.savefig('AutoEncoder_{}_{}_BER.png'.format(n_channel, k))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot = []\n",
    "for i in range(0,M):\n",
    "    temp = np.zeros(M)\n",
    "    temp[i] = 1\n",
    "    scatter_plot.append(encoder.predict(np.expand_dims(temp,axis=0)))\n",
    "scatter_plot = 1.5/2*np.array(scatter_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 112 into shape (16,2,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-498-465c0cfa730e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# ploting constellation diagram\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mscatter_plot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscatter_plot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscatter_plot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscatter_plot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#plt.axis((-2.5,2.5,-2.5,2.5))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 112 into shape (16,2,1)"
     ]
    }
   ],
   "source": [
    "# ploting constellation diagram\n",
    "import matplotlib.pyplot as plt\n",
    "scatter_plot = scatter_plot.reshape(M,2,1)\n",
    "plt.scatter(scatter_plot[:,0, :],scatter_plot[:,1, :])\n",
    "#plt.axis((-2.5,2.5,-2.5,2.5))\n",
    "plt.grid()\n",
    "plt.xlabel('I Axis')\n",
    "plt.ylabel('Q Axis')\n",
    "plt.savefig('AutoEncoder_{}_{}_Constellation.png'.format(n_channel, k))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot.shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
