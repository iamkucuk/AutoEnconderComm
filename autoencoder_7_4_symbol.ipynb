{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "# importing libs\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, GaussianNoise, Lambda\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "import random as rn\n",
    "\n",
    "def frange(x, y, jump):\n",
    "  while x < y:\n",
    "    yield x\n",
    "    x += jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "M: 16 k: 4 n:  2 R:  2.0\n"
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'frange' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ba55e3d2cf6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'M:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'k:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_channel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"R: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mEbNodB_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'frange' is not defined"
     ]
    }
   ],
   "source": [
    "# defining parameters\n",
    "k = 4\n",
    "M = 2**k\n",
    "# k = np.log2(M)\n",
    "# k = int(k)\n",
    "n_channel = 2\n",
    "R = k/n_channel\n",
    "print ('M:',M,'k:',k, \"n: \", n_channel, \"R: \", R)\n",
    "\n",
    "EbNodB_range = list(frange(0,14,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(14)\n",
    "rn.seed(14)\n",
    "np.random.seed(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generating data of size N\n",
    "N = 10000\n",
    "label = np.random.randint(M,size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating one hot encoded vectors\n",
    "data = []\n",
    "for i in label:\n",
    "    temp = np.zeros(M)\n",
    "    temp[i] = 1\n",
    "    data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(10000, 16)\n"
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "6 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n10 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n0 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n11 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n4 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n4 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n8 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n12 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n7 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
    }
   ],
   "source": [
    "temp_check = [17,23,45,67,89,96,72,250,350]\n",
    "for i in temp_check:\n",
    "    print(label[i],data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\n"
    }
   ],
   "source": [
    "# print (int(k/R))\n",
    "input_signal = Input(shape=(M,))\n",
    "encoded = Dense(M, activation='relu')(input_signal)\n",
    "encoded1 = Dense(n_channel, activation='linear')(encoded)\n",
    "encoded2 = BatchNormalization(center=False, scale=False)(encoded1)\n",
    "#encoded2 = Lambda(lambda x: 2.0/np.sqrt(2)*K.l2_normalize(x,axis=-1))(encoded1)\n",
    "\n",
    "EbNo_train = 5.01187 #  coverted 7 db of EbNo\n",
    "encoded3 = GaussianNoise(np.sqrt(1/(2*R*EbNo_train)))(encoded2)\n",
    "\n",
    "decoded = Dense(M, activation='relu')(encoded3)\n",
    "decoded1 = Dense(M, activation='softmax')(decoded)\n",
    "\n",
    "autoencoder = Model(input_signal, decoded1)\n",
    "#sgd = SGD(lr=0.001)\n",
    "autoencoder.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 16)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 16)                272       \n_________________________________________________________________\ndense_2 (Dense)              (None, 2)                 34        \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 2)                 4         \n_________________________________________________________________\ngaussian_noise_1 (GaussianNo (None, 2)                 0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 16)                48        \n_________________________________________________________________\ndense_4 (Dense)              (None, 16)                272       \n=================================================================\nTotal params: 630\nTrainable params: 626\nNon-trainable params: 4\n_________________________________________________________________\nNone\n"
    }
   ],
   "source": [
    "print (autoencoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_val = 1500\n",
    "val_label = np.random.randint(M,size=N_val)\n",
    "val_data = []\n",
    "for i in val_label:\n",
    "    temp = np.zeros(M)\n",
    "    temp[i] = 1\n",
    "    val_data.append(temp)\n",
    "val_data = np.array(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "- val_loss: 0.0020\nEpoch 816/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1852 - val_loss: 0.0021\nEpoch 817/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1965 - val_loss: 0.0022\nEpoch 818/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1966 - val_loss: 0.0020\nEpoch 819/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1856 - val_loss: 0.0020\nEpoch 820/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1871 - val_loss: 0.0020\nEpoch 821/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1963 - val_loss: 0.0021\nEpoch 822/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1959 - val_loss: 0.0021\nEpoch 823/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1848 - val_loss: 0.0020\nEpoch 824/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1818 - val_loss: 0.0020\nEpoch 825/1000\n10000/10000 [==============================] - 0s 4us/step - loss: 0.1909 - val_loss: 0.0020\nEpoch 826/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1788 - val_loss: 0.0021\nEpoch 827/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1836 - val_loss: 0.0020\nEpoch 828/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1879 - val_loss: 0.0020\nEpoch 829/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1913 - val_loss: 0.0021\nEpoch 830/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1937 - val_loss: 0.0021\nEpoch 831/1000\n10000/10000 [==============================] - 0s 4us/step - loss: 0.1881 - val_loss: 0.0020\nEpoch 832/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1979 - val_loss: 0.0021\nEpoch 833/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1988 - val_loss: 0.0020\nEpoch 834/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1858 - val_loss: 0.0020\nEpoch 835/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1767 - val_loss: 0.0020\nEpoch 836/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.2041 - val_loss: 0.0021\nEpoch 837/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1876 - val_loss: 0.0021\nEpoch 838/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.2009 - val_loss: 0.0020\nEpoch 839/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1957 - val_loss: 0.0020\nEpoch 840/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1927 - val_loss: 0.0020\nEpoch 841/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1861 - val_loss: 0.0021\nEpoch 842/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1832 - val_loss: 0.0021\nEpoch 843/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1973 - val_loss: 0.0020\nEpoch 844/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1823 - val_loss: 0.0020\nEpoch 845/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1905 - val_loss: 0.0020\nEpoch 846/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1834 - val_loss: 0.0021\nEpoch 847/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1930 - val_loss: 0.0020\nEpoch 848/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1970 - val_loss: 0.0020\nEpoch 849/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1840 - val_loss: 0.0020\nEpoch 850/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1965 - val_loss: 0.0020\nEpoch 851/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.2109 - val_loss: 0.0020\nEpoch 852/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1898 - val_loss: 0.0019\nEpoch 853/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1866 - val_loss: 0.0021\nEpoch 854/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1912 - val_loss: 0.0019\nEpoch 855/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1818 - val_loss: 0.0020\nEpoch 856/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1953 - val_loss: 0.0020\nEpoch 857/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1963 - val_loss: 0.0020\nEpoch 858/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1994 - val_loss: 0.0020\nEpoch 859/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1998 - val_loss: 0.0020\nEpoch 860/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1872 - val_loss: 0.0020\nEpoch 861/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1834 - val_loss: 0.0020\nEpoch 862/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.2064 - val_loss: 0.0020\nEpoch 863/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1890 - val_loss: 0.0020\nEpoch 864/1000\n10000/10000 [==============================] - 0s 4us/step - loss: 0.1939 - val_loss: 0.0020\nEpoch 865/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1854 - val_loss: 0.0020\nEpoch 866/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1847 - val_loss: 0.0020\nEpoch 867/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1888 - val_loss: 0.0020\nEpoch 868/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1966 - val_loss: 0.0021\nEpoch 869/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1960 - val_loss: 0.0022\nEpoch 870/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1916 - val_loss: 0.0020\nEpoch 871/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1920 - val_loss: 0.0020\nEpoch 872/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1822 - val_loss: 0.0020\nEpoch 873/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1889 - val_loss: 0.0020\nEpoch 874/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1889 - val_loss: 0.0021\nEpoch 875/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1907 - val_loss: 0.0019\nEpoch 876/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1866 - val_loss: 0.0019\nEpoch 877/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.2112 - val_loss: 0.0020\nEpoch 878/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1958 - val_loss: 0.0020\nEpoch 879/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1918 - val_loss: 0.0021\nEpoch 880/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1826 - val_loss: 0.0019\nEpoch 881/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1910 - val_loss: 0.0020\nEpoch 882/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.2082 - val_loss: 0.0020\nEpoch 883/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1858 - val_loss: 0.0020\nEpoch 884/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1976 - val_loss: 0.0019\nEpoch 885/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1846 - val_loss: 0.0019\nEpoch 886/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.2057 - val_loss: 0.0019\nEpoch 887/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1835 - val_loss: 0.0019\nEpoch 888/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1873 - val_loss: 0.0020\nEpoch 889/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1897 - val_loss: 0.0019\nEpoch 890/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1731 - val_loss: 0.0019\nEpoch 891/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1922 - val_loss: 0.0019\nEpoch 892/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1902 - val_loss: 0.0020\nEpoch 893/1000\n10000/10000 [==============================] - 0s 4us/step - loss: 0.1801 - val_loss: 0.0020\nEpoch 894/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1877 - val_loss: 0.0020\nEpoch 895/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.2129 - val_loss: 0.0019\nEpoch 896/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1866 - val_loss: 0.0020\nEpoch 897/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1987 - val_loss: 0.0020\nEpoch 898/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1949 - val_loss: 0.0020\nEpoch 899/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1916 - val_loss: 0.0019\nEpoch 900/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1873 - val_loss: 0.0020\nEpoch 901/1000\n10000/10000 [==============================] - 0s 4us/step - loss: 0.1997 - val_loss: 0.0020\nEpoch 902/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1859 - val_loss: 0.0019\nEpoch 903/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1862 - val_loss: 0.0019\nEpoch 904/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1852 - val_loss: 0.0020\nEpoch 905/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1803 - val_loss: 0.0020\nEpoch 906/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1954 - val_loss: 0.0019\nEpoch 907/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1968 - val_loss: 0.0019\nEpoch 908/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1927 - val_loss: 0.0020\nEpoch 909/1000\n10000/10000 [==============================] - 0s 4us/step - loss: 0.1820 - val_loss: 0.0019\nEpoch 910/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1835 - val_loss: 0.0019\nEpoch 911/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1979 - val_loss: 0.0019\nEpoch 912/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1796 - val_loss: 0.0019\nEpoch 913/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1847 - val_loss: 0.0019\nEpoch 914/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.2036 - val_loss: 0.0019\nEpoch 915/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1846 - val_loss: 0.0019\nEpoch 916/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1804 - val_loss: 0.0019\nEpoch 917/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1849 - val_loss: 0.0019\nEpoch 918/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1901 - val_loss: 0.0019\nEpoch 919/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1872 - val_loss: 0.0019\nEpoch 920/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.2024 - val_loss: 0.0019\nEpoch 921/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1953 - val_loss: 0.0019\nEpoch 922/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1959 - val_loss: 0.0020\nEpoch 923/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1891 - val_loss: 0.0019\nEpoch 924/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1967 - val_loss: 0.0020\nEpoch 925/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1784 - val_loss: 0.0019\nEpoch 926/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1993 - val_loss: 0.0019\nEpoch 927/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1790 - val_loss: 0.0019\nEpoch 928/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1803 - val_loss: 0.0019\nEpoch 929/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.2021 - val_loss: 0.0020\nEpoch 930/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.2003 - val_loss: 0.0019\nEpoch 931/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1812 - val_loss: 0.0019\nEpoch 932/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1957 - val_loss: 0.0019\nEpoch 933/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1981 - val_loss: 0.0020\nEpoch 934/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1825 - val_loss: 0.0019\nEpoch 935/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1937 - val_loss: 0.0019\nEpoch 936/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1886 - val_loss: 0.0019\nEpoch 937/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1862 - val_loss: 0.0019\nEpoch 938/1000\n10000/10000 [==============================] - 0s 4us/step - loss: 0.2012 - val_loss: 0.0020\nEpoch 939/1000\n10000/10000 [==============================] - 0s 4us/step - loss: 0.1829 - val_loss: 0.0019\nEpoch 940/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1803 - val_loss: 0.0020\nEpoch 941/1000\n10000/10000 [==============================] - 0s 4us/step - loss: 0.1956 - val_loss: 0.0019\nEpoch 942/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1876 - val_loss: 0.0019\nEpoch 943/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1737 - val_loss: 0.0019\nEpoch 944/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1865 - val_loss: 0.0019\nEpoch 945/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1820 - val_loss: 0.0019\nEpoch 946/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1975 - val_loss: 0.0019\nEpoch 947/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1881 - val_loss: 0.0019\nEpoch 948/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1969 - val_loss: 0.0019\nEpoch 949/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1801 - val_loss: 0.0019\nEpoch 950/1000\n10000/10000 [==============================] - 0s 4us/step - loss: 0.1815 - val_loss: 0.0019\nEpoch 951/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1921 - val_loss: 0.0019\nEpoch 952/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1829 - val_loss: 0.0019\nEpoch 953/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1746 - val_loss: 0.0019\nEpoch 954/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1869 - val_loss: 0.0019\nEpoch 955/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1944 - val_loss: 0.0019\nEpoch 956/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1960 - val_loss: 0.0018\nEpoch 957/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1936 - val_loss: 0.0019\nEpoch 958/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1960 - val_loss: 0.0019\nEpoch 959/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1897 - val_loss: 0.0019\nEpoch 960/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1893 - val_loss: 0.0019\nEpoch 961/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1924 - val_loss: 0.0018\nEpoch 962/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1889 - val_loss: 0.0019\nEpoch 963/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1875 - val_loss: 0.0019\nEpoch 964/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1983 - val_loss: 0.0019\nEpoch 965/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1826 - val_loss: 0.0019\nEpoch 966/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1878 - val_loss: 0.0019\nEpoch 967/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1967 - val_loss: 0.0019\nEpoch 968/1000\n10000/10000 [==============================] - 0s 4us/step - loss: 0.1913 - val_loss: 0.0019\nEpoch 969/1000\n10000/10000 [==============================] - 0s 4us/step - loss: 0.1985 - val_loss: 0.0020\nEpoch 970/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1954 - val_loss: 0.0019\nEpoch 971/1000\n10000/10000 [==============================] - 0s 4us/step - loss: 0.1905 - val_loss: 0.0019\nEpoch 972/1000\n10000/10000 [==============================] - 0s 4us/step - loss: 0.1942 - val_loss: 0.0018\nEpoch 973/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1769 - val_loss: 0.0019\nEpoch 974/1000\n10000/10000 [==============================] - 0s 4us/step - loss: 0.1925 - val_loss: 0.0018\nEpoch 975/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1986 - val_loss: 0.0019\nEpoch 976/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1921 - val_loss: 0.0019\nEpoch 977/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1916 - val_loss: 0.0018\nEpoch 978/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1859 - val_loss: 0.0019\nEpoch 979/1000\n10000/10000 [==============================] - 0s 4us/step - loss: 0.1810 - val_loss: 0.0019\nEpoch 980/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1873 - val_loss: 0.0019\nEpoch 981/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1823 - val_loss: 0.0018\nEpoch 982/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1945 - val_loss: 0.0018\nEpoch 983/1000\n10000/10000 [==============================] - 0s 4us/step - loss: 0.1884 - val_loss: 0.0019\nEpoch 984/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1865 - val_loss: 0.0019\nEpoch 985/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1816 - val_loss: 0.0018\nEpoch 986/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1873 - val_loss: 0.0018\nEpoch 987/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1882 - val_loss: 0.0019\nEpoch 988/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1877 - val_loss: 0.0019\nEpoch 989/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1925 - val_loss: 0.0018\nEpoch 990/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1863 - val_loss: 0.0019\nEpoch 991/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1933 - val_loss: 0.0018\nEpoch 992/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1928 - val_loss: 0.0019\nEpoch 993/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1807 - val_loss: 0.0018\nEpoch 994/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1986 - val_loss: 0.0019\nEpoch 995/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1994 - val_loss: 0.0018\nEpoch 996/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1769 - val_loss: 0.0019\nEpoch 997/1000\n10000/10000 [==============================] - 0s 4us/step - loss: 0.1794 - val_loss: 0.0018\nEpoch 998/1000\n10000/10000 [==============================] - 0s 4us/step - loss: 0.1926 - val_loss: 0.0019\nEpoch 999/1000\n10000/10000 [==============================] - 0s 3us/step - loss: 0.1844 - val_loss: 0.0019\nEpoch 1000/1000\n10000/10000 [==============================] - 0s 4us/step - loss: 0.1808 - val_loss: 0.0019\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.callbacks.History at 0x7f2dda65bd68>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "autoencoder.fit(data, data,\n",
    "                epochs=1000,\n",
    "                batch_size=300,\n",
    "                validation_data=(val_data, val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "#autoencoder.save('4_7_symbol_autoencoder_v_best.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#autoencoder_loaded = load_model('4_7_symbol_autoencoder_v_best.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = Model(input_signal, encoded2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_input = Input(shape=(n_channel,))\n",
    "\n",
    "deco = autoencoder.layers[-2](encoded_input)\n",
    "deco = autoencoder.layers[-1](deco)\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, deco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 45000\n",
    "test_label = np.random.randint(M,size=N)\n",
    "test_data = []\n",
    "\n",
    "for i in test_label:\n",
    "    temp = np.zeros(M)\n",
    "    temp[i] = 1\n",
    "    test_data.append(temp)\n",
    "    \n",
    "test_data = np.array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1.0 2\n"
    }
   ],
   "source": [
    "temp_test = 6\n",
    "print (test_data[temp_test][test_label[temp_test]],test_label[temp_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.engine.training.Model at 0x7f2ddc173f98>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'frange' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-843045d55e92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mEbNodB_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEbNodB_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEbNodB_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mEbNo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10.0\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEbNodB_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnoise_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mEbNo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'frange' is not defined"
     ]
    }
   ],
   "source": [
    "EbNodB_range = list(frange(0,14,0.5))\n",
    "ber = [None]*len(EbNodB_range)\n",
    "for n in range(0,len(EbNodB_range)):\n",
    "    EbNo=10.0**(EbNodB_range[n]/10.0)\n",
    "    noise_std = np.sqrt(1/(2*R*EbNo))\n",
    "    noise_mean = 0\n",
    "    no_errors = 0\n",
    "    nn = N\n",
    "    noise = noise_std * np.random.randn(nn,n_channel)\n",
    "    encoded_signal = encoder.predict(test_data) \n",
    "    final_signal = encoded_signal + noise\n",
    "    pred_final_signal =  decoder.predict(final_signal)\n",
    "    pred_output = np.argmax(pred_final_signal,axis=1)\n",
    "    no_errors = (pred_output != test_label)\n",
    "    no_errors =  no_errors.astype(int).sum()\n",
    "    ber[n] = no_errors / nn \n",
    "    print ('SNR:',EbNodB_range[n],'BER:',ber[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'EbNodB_range' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f5e1d9be4861>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEbNodB_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Autoencoder({}, {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_channel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#plt.plot(list(EbNodB_range), ber_theory, 'ro-',label='BPSK BER')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SNR Range'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EbNodB_range' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(EbNodB_range, ber, 'bo',label='Autoencoder({}, {})'.format(n_channel, k))\n",
    "#plt.plot(list(EbNodB_range), ber_theory, 'ro-',label='BPSK BER')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('SNR Range')\n",
    "plt.ylabel('Block Error Rate')\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right',ncol = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "plt.savefig('AutoEncoder_{}_{}_BER_matplotlib'.format(n_channel, k))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scatter_plot = []\n",
    "for i in range(0,M):\n",
    "    temp = np.zeros(M)\n",
    "    temp[i] = 1\n",
    "    scatter_plot.append(encoder.predict(np.expand_dims(temp,axis=0)))\n",
    "scatter_plot = 1.5/2*np.array(scatter_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"262.19625pt\" version=\"1.1\" viewBox=\"0 0 394.160938 262.19625\" width=\"394.160938pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 262.19625 \nL 394.160938 262.19625 \nL 394.160938 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 52.160938 224.64 \nL 386.960938 224.64 \nL 386.960938 7.2 \nL 52.160938 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"PathCollection_1\">\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"mff2a4fd4e3\" style=\"stroke:#1f77b4;\"/>\n    </defs>\n    <g clip-path=\"url(#p67145b0cb6)\">\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"263.059105\" xlink:href=\"#mff2a4fd4e3\" y=\"199.229167\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"181.832184\" xlink:href=\"#mff2a4fd4e3\" y=\"17.083636\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"276.975332\" xlink:href=\"#mff2a4fd4e3\" y=\"30.678581\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"154.399502\" xlink:href=\"#mff2a4fd4e3\" y=\"114.691679\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"290.718466\" xlink:href=\"#mff2a4fd4e3\" y=\"87.975408\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"172.97371\" xlink:href=\"#mff2a4fd4e3\" y=\"214.756364\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"105.565174\" xlink:href=\"#mff2a4fd4e3\" y=\"169.56841\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"290.908559\" xlink:href=\"#mff2a4fd4e3\" y=\"143.93027\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"362.807679\" xlink:href=\"#mff2a4fd4e3\" y=\"58.150693\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"198.215254\" xlink:href=\"#mff2a4fd4e3\" y=\"161.31194\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"207.518646\" xlink:href=\"#mff2a4fd4e3\" y=\"70.915665\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"111.434481\" xlink:href=\"#mff2a4fd4e3\" y=\"61.163253\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"231.546219\" xlink:href=\"#mff2a4fd4e3\" y=\"116.486299\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"371.742756\" xlink:href=\"#mff2a4fd4e3\" y=\"118.743818\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"67.379119\" xlink:href=\"#mff2a4fd4e3\" y=\"114.275241\"/>\n     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"358.907771\" xlink:href=\"#mff2a4fd4e3\" y=\"182.333626\"/>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#p67145b0cb6)\" d=\"M 103.722525 224.64 \nL 103.722525 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m2f2c127e7e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"103.722525\" xlink:href=\"#m2f2c127e7e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- −1.0 -->\n      <defs>\n       <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(91.581119 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#p67145b0cb6)\" d=\"M 166.024572 224.64 \nL 166.024572 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"166.024572\" xlink:href=\"#m2f2c127e7e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- −0.5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(153.883166 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#p67145b0cb6)\" d=\"M 228.326619 224.64 \nL 228.326619 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"228.326619\" xlink:href=\"#m2f2c127e7e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0.0 -->\n      <g transform=\"translate(220.375057 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#p67145b0cb6)\" d=\"M 290.628666 224.64 \nL 290.628666 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"290.628666\" xlink:href=\"#m2f2c127e7e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0.5 -->\n      <g transform=\"translate(282.677104 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#p67145b0cb6)\" d=\"M 352.930713 224.64 \nL 352.930713 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"352.930713\" xlink:href=\"#m2f2c127e7e\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 1.0 -->\n      <g transform=\"translate(344.979151 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_6\">\n     <!-- I Axis -->\n     <defs>\n      <path d=\"M 9.8125 72.90625 \nL 19.671875 72.90625 \nL 19.671875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-73\"/>\n      <path id=\"DejaVuSans-32\"/>\n      <path d=\"M 34.1875 63.1875 \nL 20.796875 26.90625 \nL 47.609375 26.90625 \nz\nM 28.609375 72.90625 \nL 39.796875 72.90625 \nL 67.578125 0 \nL 57.328125 0 \nL 50.6875 18.703125 \nL 17.828125 18.703125 \nL 11.1875 0 \nL 0.78125 0 \nz\n\" id=\"DejaVuSans-65\"/>\n      <path d=\"M 54.890625 54.6875 \nL 35.109375 28.078125 \nL 55.90625 0 \nL 45.3125 0 \nL 29.390625 21.484375 \nL 13.484375 0 \nL 2.875 0 \nL 24.125 28.609375 \nL 4.6875 54.6875 \nL 15.28125 54.6875 \nL 29.78125 35.203125 \nL 44.28125 54.6875 \nz\n\" id=\"DejaVuSans-120\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n     </defs>\n     <g transform=\"translate(206.123438 252.916562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-73\"/>\n      <use x=\"29.492188\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"61.279297\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"129.6875\" xlink:href=\"#DejaVuSans-120\"/>\n      <use x=\"188.867188\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"216.650391\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#p67145b0cb6)\" d=\"M 52.160938 192.833348 \nL 386.960938 192.833348 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"me52810c44c\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.160938\" xlink:href=\"#me52810c44c\" y=\"192.833348\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- −1.0 -->\n      <g transform=\"translate(20.878125 196.632566)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#p67145b0cb6)\" d=\"M 52.160938 154.705149 \nL 386.960938 154.705149 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.160938\" xlink:href=\"#me52810c44c\" y=\"154.705149\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- −0.5 -->\n      <g transform=\"translate(20.878125 158.504368)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#p67145b0cb6)\" d=\"M 52.160938 116.57695 \nL 386.960938 116.57695 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.160938\" xlink:href=\"#me52810c44c\" y=\"116.57695\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.0 -->\n      <g transform=\"translate(29.257812 120.376169)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#p67145b0cb6)\" d=\"M 52.160938 78.448751 \nL 386.960938 78.448751 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.160938\" xlink:href=\"#me52810c44c\" y=\"78.448751\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.5 -->\n      <g transform=\"translate(29.257812 82.24797)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#p67145b0cb6)\" d=\"M 52.160938 40.320553 \nL 386.960938 40.320553 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.160938\" xlink:href=\"#me52810c44c\" y=\"40.320553\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 1.0 -->\n      <g transform=\"translate(29.257812 44.119772)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_12\">\n     <!-- Q Axis -->\n     <defs>\n      <path d=\"M 39.40625 66.21875 \nQ 28.65625 66.21875 22.328125 58.203125 \nQ 16.015625 50.203125 16.015625 36.375 \nQ 16.015625 22.609375 22.328125 14.59375 \nQ 28.65625 6.59375 39.40625 6.59375 \nQ 50.140625 6.59375 56.421875 14.59375 \nQ 62.703125 22.609375 62.703125 36.375 \nQ 62.703125 50.203125 56.421875 58.203125 \nQ 50.140625 66.21875 39.40625 66.21875 \nz\nM 53.21875 1.3125 \nL 66.21875 -12.890625 \nL 54.296875 -12.890625 \nL 43.5 -1.21875 \nQ 41.890625 -1.3125 41.03125 -1.359375 \nQ 40.1875 -1.421875 39.40625 -1.421875 \nQ 24.03125 -1.421875 14.8125 8.859375 \nQ 5.609375 19.140625 5.609375 36.375 \nQ 5.609375 53.65625 14.8125 63.9375 \nQ 24.03125 74.21875 39.40625 74.21875 \nQ 54.734375 74.21875 63.90625 63.9375 \nQ 73.09375 53.65625 73.09375 36.375 \nQ 73.09375 23.6875 67.984375 14.640625 \nQ 62.890625 5.609375 53.21875 1.3125 \nz\n\" id=\"DejaVuSans-81\"/>\n     </defs>\n     <g transform=\"translate(14.798437 131.818437)rotate(-90)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-81\"/>\n      <use x=\"78.710938\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"110.498047\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"178.90625\" xlink:href=\"#DejaVuSans-120\"/>\n      <use x=\"238.085938\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"265.869141\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 52.160938 224.64 \nL 52.160938 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 386.960938 224.64 \nL 386.960938 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 52.160938 224.64 \nL 386.960938 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 52.160938 7.2 \nL 386.960938 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p67145b0cb6\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"52.160938\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# ploting constellation diagram\n",
    "import matplotlib.pyplot as plt\n",
    "scatter_plot = scatter_plot.reshape(M,2,1)\n",
    "plt.scatter(scatter_plot[:,0, :],scatter_plot[:,1, :])\n",
    "#plt.axis((-2.5,2.5,-2.5,2.5))\n",
    "plt.grid()\n",
    "plt.xlabel('I Axis')\n",
    "plt.ylabel('Q Axis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(16, 2, 1)"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "scatter_plot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}